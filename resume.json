{
  "basics": {
    "name": "John Karabudak",
    "email": "hello@johnthenerd.com",
    "website": "johnthenerd.com",
    "summary": "DevOps professional with a strong background in automation, Linux systems, and cloud infrastructure. Experienced in optimizing data pipelines, driving innovation, and implementing effective security measures. Proficient in Docker, Ansible, and CloudFormation, delivering performance enhancements and cost savings.",
    "location": {
      "city": "St. John's",
      "region": "Newfoundland and Labrador"
    },
    "profiles": [
      {
        "network": "GitHub",
        "username": "JohnTheNerd",
        "url": "github.com/JohnTheNerd"
      },
      {
        "network": "LinkedIn",
        "username": "john-karabudak",
        "url": "linkedin.com/in/john-karabudak"
      }
    ]
  },
  "work": [
    {
      "position": "Software Developer",
      "name": "WSP Environment & Infrastructure",
      "startDate": "2017-05",
      "highlights": [
        "Spearheaded our efforts to pay down technical debt efforts, decreasing our after-hours pages by over 50%.",
        "Optimized our weather portal performance, increasing our Google PageSpeed Insights score by 100%.",
        "Singlehandedly planned and executed all technical aspects of our group's COVID-19 business continuity plan.",
        "Played a key role in migrating our group to the latest meteorological display and analysis solution used operationally by the United States National Weather Service, processing over a terabyte of data every day.",
        "Innovated our data ingestion pipeline to horizontally scale AWS EC2 spot instances and dramatically improve processing times while achieving up to 70% cost savings.",
        "Achieved over 10% savings in our group's AWS bill by using a combination of EC2 spot instances, AWS S3 Glacier Deep Archive, AWS Lambda, AWS VPC Endpoints, and other technologies.",
        "Improved data ingestion times by 2000% by designing an on-event data ingestion pipeline.",
        "Spearheaded the security culture within our group, including the implementation of network-level access control policies for microservices, short-lived developer access keys, TPM-backed VPN authentication, and much more."
      ]
    }
  ],
  "education": [
    {
      "institution": "Memorial University of Newfoundland",
      "studyType": "Bachelor of Science (Computer Science)",
      "startDate": "2014-09",
      "endDate": "2020-09"
    }
  ],
  "projects": [
    {
      "name": "PySarra",
      "summary": "A Python client for Environment Canada's MQTT-based Sarracenia service that is designed to be easy to use.",
      "url": "https://github.com/JohnTheNerd/PySarra"
    },
    {
      "name": "serial2mqtt",
      "summary": "A Python microservice that streams LDJSON (Line-Delimited JSON) data from a serial port to a given MQTT broker.",
      "url": "https://github.com/JohnTheNerd/serial2mqtt"
    },
    {
      "name": "simple-gluster-ansible",
      "summary": "An Ansible playbook to install and configure GlusterFS that is designed to be simple, with TLS encryption pre-configured.",
      "url": "https://github.com/JohnTheNerd/simple-gluster-ansible"
    },
    {
      "name": "tarsnap-cron-docker",
      "summary": "A Docker container image that uses Tarsnap to periodically and automatically back up your data.",
      "url": "https://github.com/JohnTheNerd/tarsnap-cron-docker"
    },
    {
      "name": "TurtleTale",
      "summary": "A browser-based 2D platformer about a young turtle, complete with a level editor, an in-game shop, and toggleable cheats.",
      "url": "https://johnthenerd.com/?turtletale"
    },
    {
        "name": "WOLRelay",
        "summary": "A Python Wake-on-LAN forwarder that is able to listen for ARP reply packets to track IP addresses without any agent process running on the target machine. JavaScript frontend, Flask backend.",
        "url": "https://github.com/JohnTheNerd/WOLRelay"
    }
  ],
  "references": [
    {
      "contact": "In order to protect the privacy of my references from online scrapers, it is not publicly available. I can happily provide it upon request, though!"
    }
]
}
